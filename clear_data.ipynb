{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb76b2f",
   "metadata": {},
   "source": [
    "# Raw data -> Reuse distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3779004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882836ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_data/'\n",
    "hist = {}\n",
    "second_hist = {}\n",
    "fnames = []\n",
    "for file in os.listdir(path):\n",
    "    if file[-9:] != '_2048.out':\n",
    "        continue\n",
    "    id_ctr = 0\n",
    "    hist_list = []\n",
    "    with open(path+file) as f:\n",
    "        lines = f.readlines()\n",
    "        ctr = 0\n",
    "        conf_values = ['id']\n",
    "        while lines[ctr] != \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "            ctr += 1\n",
    "        ctr += 1\n",
    "        while lines[ctr] != \"~~~~~~~~~~Reuse Distance Profiler output end~~~~~~~~~~\\n\":\n",
    "            x, y, z = lines[ctr].split()\n",
    "            conf_values.append(x)\n",
    "            second_hist[x] = int(y)\n",
    "            ctr += 1\n",
    "        while len(lines) - 20 > ctr:\n",
    "            while lines[ctr] != \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "                ctr += 1\n",
    "            hist['id'] = file[:-8] + str(id_ctr)\n",
    "            id_ctr += 1\n",
    "            ctr += 1\n",
    "            while lines[ctr] != \"~~~~~~~~~~Reuse Distance Profiler output end~~~~~~~~~~\\n\":\n",
    "                x, y, z = lines[ctr].split()\n",
    "                hist[x] = int(y) - second_hist[x]\n",
    "                second_hist[x] = int(y)\n",
    "                ctr += 1\n",
    "            hist_list.append(hist.copy())\n",
    "    id_ctr -= 1       # Since we don't keep the last one\n",
    "    fnames.append(file[:-9])\n",
    "    print(f'Printing: '+'reuse_distances/'+file[:-9]+'.csv'+f', {len(hist_list)} rds')\n",
    "    with open('reuse_distances/'+file[:-9]+'.csv', 'w', newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=conf_values)\n",
    "        writer.writeheader()\n",
    "        # writer.writerow(second_hist)    # Final/full histogram\n",
    "        for hst in hist_list[:-1]:     # (last one's all 0 and first one has warmup instructions)\n",
    "            writer.writerow(hst)        # In between histograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419f97c",
   "metadata": {},
   "source": [
    "# Raw data -> Total accesses, misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62d80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6531dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
     ]
    }
   ],
   "source": [
    "path = '../ce_raw_data/ship_llc/'\n",
    "id_ctr = 0\n",
    "columns = ['id','1024','2048','4096','8192']\n",
    "l1d_full = pd.DataFrame()\n",
    "l2c_full = pd.DataFrame()\n",
    "llc_full = pd.DataFrame()\n",
    "l1d_accesses_full = pd.DataFrame()\n",
    "l2c_accesses_full = pd.DataFrame()\n",
    "llc_accesses_full = pd.DataFrame()\n",
    "l1d_misses_full = pd.DataFrame()\n",
    "l2c_misses_full = pd.DataFrame()\n",
    "llc_misses_full = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    if file[-9:] != '_2048.out':\n",
    "        continue\n",
    "    l1d_small = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    l2c_small = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    llc_small = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    l1d_accesses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    l2c_accesses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    llc_accesses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    l1d_misses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    l2c_misses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    llc_misses = pd.DataFrame(0, index=np.arange(749), columns=columns)\n",
    "    # print(file)\n",
    "    for c in columns[1:]:\n",
    "        fname = file[:-9] + '_' + c + '.out'\n",
    "        checker = False\n",
    "        with open(path+fname) as f:\n",
    "            lines = f.readlines()\n",
    "            ctr = 0\n",
    "            prev_misses_l1d = 0.\n",
    "            prev_accesses_l1d = 0.\n",
    "            prev_misses_l2c = 0.\n",
    "            prev_accesses_l2c = 0.\n",
    "            prev_misses_llc = 0.\n",
    "            prev_accesses_llc = 0.\n",
    "            for line in lines:\n",
    "                if line != \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "                    checker=True\n",
    "                if line[:14] == \"cpu0_L1D TOTAL\":\n",
    "                    ctr+=1\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_l1d = int(line.split()[7])\n",
    "                        prev_accesses_l1d = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        l1d_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_l1d\n",
    "                        prev_misses_l1d = int(line.split()[7])\n",
    "                        l1d_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_l1d\n",
    "                        prev_accesses_l1d = int(line.split()[3])\n",
    "                        if l1d_accesses[c][ctr-2] == 0: continue\n",
    "                        l1d_small[c][ctr-2] = float(l1d_misses[c][ctr-2])/float(l1d_accesses[c][ctr-2])\n",
    "                if line[:14] == \"cpu0_L2C TOTAL\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_l2c = int(line.split()[7])\n",
    "                        prev_accesses_l2c = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        l2c_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_l2c\n",
    "                        prev_misses_l2c = int(line.split()[7])\n",
    "                        l2c_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_l2c\n",
    "                        prev_accesses_l2c = int(line.split()[3])\n",
    "                        if l2c_accesses[c][ctr-2] == 0: continue\n",
    "                        l2c_small[c][ctr-2] = float(l2c_misses[c][ctr-2])/float(l2c_accesses[c][ctr-2])\n",
    "                if line[:9] == \"LLC TOTAL\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_llc = int(line.split()[7])\n",
    "                        prev_accesses_llc = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        llc_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_llc\n",
    "                        prev_misses_llc = int(line.split()[7])\n",
    "                        llc_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_llc\n",
    "                        prev_accesses_llc = int(line.split()[3])\n",
    "                        if llc_accesses[c][ctr-2] == 0: continue\n",
    "                        llc_small[c][ctr-2] = float(llc_misses[c][ctr-2])/float(llc_accesses[c][ctr-2])\n",
    "            if not checker or ctr != 751:\n",
    "                print(\"\\n Error:\", fname) # Check if a file didn't finish correctly\n",
    "    print(\"|\",end=\"\")\n",
    "    # print(l1d_small)\n",
    "    l1d_small['id'] = file[:-9] + '_' + l1d_small.index.map(str)\n",
    "    l2c_small['id'] = file[:-9] + '_' + l2c_small.index.map(str)\n",
    "    llc_small['id'] = file[:-9] + '_' + llc_small.index.map(str)\n",
    "    l1d_accesses['id'] = file[:-9] + '_' + l1d_accesses.index.map(str)\n",
    "    l2c_accesses['id'] = file[:-9] + '_' + l2c_accesses.index.map(str)\n",
    "    llc_accesses['id'] = file[:-9] + '_' + llc_accesses.index.map(str)\n",
    "    l1d_misses['id'] = file[:-9] + '_' + l1d_misses.index.map(str)\n",
    "    l2c_misses['id'] = file[:-9] + '_' + l2c_misses.index.map(str)\n",
    "    llc_misses['id'] = file[:-9] + '_' + llc_misses.index.map(str)\n",
    "    \n",
    "    l1d_full = pd.concat([l1d_full, l1d_small], ignore_index = True)\n",
    "    l2c_full = pd.concat([l2c_full, l2c_small], ignore_index = True)\n",
    "    llc_full = pd.concat([llc_full, llc_small], ignore_index = True)\n",
    "    l1d_accesses_full = pd.concat([l1d_accesses_full, l1d_accesses], ignore_index = True)\n",
    "    l2c_accesses_full = pd.concat([l2c_accesses_full, l2c_accesses], ignore_index = True)\n",
    "    llc_accesses_full = pd.concat([llc_accesses_full, llc_accesses], ignore_index = True)\n",
    "    l1d_misses_full = pd.concat([l1d_misses_full, l1d_misses], ignore_index = True)\n",
    "    l2c_misses_full = pd.concat([l2c_misses_full, l2c_misses], ignore_index = True)\n",
    "    llc_misses_full = pd.concat([llc_misses_full, llc_misses], ignore_index = True)\n",
    "    # print(llc_misses_full)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71f0146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id  1024  2048  4096  8192\n",
      "0       400.perlbench-41B_0   994   994   994   994\n",
      "1       400.perlbench-41B_1  1262  1262  1262  1262\n",
      "2       400.perlbench-41B_2   761   761   761   761\n",
      "3       400.perlbench-41B_3   464   464   464   464\n",
      "4       400.perlbench-41B_4   831   831   831   831\n",
      "...                     ...   ...   ...   ...   ...\n",
      "141556     657.xz_s-56B_744   838   838   838   838\n",
      "141557     657.xz_s-56B_745   836   836   836   836\n",
      "141558     657.xz_s-56B_746   838   838   838   838\n",
      "141559     657.xz_s-56B_747   836   836   836   836\n",
      "141560     657.xz_s-56B_748   836   836   836   836\n",
      "\n",
      "[141561 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(l2c_accesses_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4118d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l1d_accesses_full)\n",
    "print(llc_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a501408",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = 'ship_cache'\n",
    "l1d_full.to_csv(cache_path + '/l1d_miss_ratio.csv',index=False)\n",
    "l2c_full.to_csv(cache_path + '/l2c_miss_ratio.csv',index=False)\n",
    "llc_full.to_csv(cache_path + '/llc_miss_ratio.csv',index=False)\n",
    "l1d_accesses_full.to_csv(cache_path + '/l1d_accesses.csv',index=False)\n",
    "l2c_accesses_full.to_csv(cache_path + '/l2c_accesses.csv',index=False)\n",
    "llc_accesses_full.to_csv(cache_path + '/llc_accesses.csv',index=False)\n",
    "l1d_misses_full.to_csv(cache_path + '/l1d_misses.csv',index=False)\n",
    "l2c_misses_full.to_csv(cache_path + '/l2c_misses.csv',index=False)\n",
    "llc_misses_full.to_csv(cache_path + '/llc_misses.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b752935",
   "metadata": {},
   "source": [
    "# Raw data -> writeback accesses, misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42011bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../ce_raw_data/raw_data/'\n",
    "id_ctr = 0\n",
    "columns = ['id','32','64','128','256','512','1024','2048','4096','8192']\n",
    "wb_accesses_full = pd.DataFrame()\n",
    "wb_misses_full = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    if file[-9:] != '_2048.out':\n",
    "        continue\n",
    "    wb_accesses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    wb_misses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    for c in columns[1:]:\n",
    "        fname = file[:-9] + '_' + c + '.out'\n",
    "        checker = False\n",
    "        with open(path+fname) as f:\n",
    "            lines = f.readlines()\n",
    "            ctr = 0\n",
    "            prev_misses_l1d = 0.\n",
    "            prev_accesses_l1d = 0.\n",
    "            prev_misses_wb = 0.\n",
    "            prev_accesses_wb = 0.\n",
    "            for line in lines:\n",
    "                if line == \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "                    checker=True\n",
    "                if line[:14] == \"cpu0_L1D TOTAL\":\n",
    "                    ctr+=1\n",
    "                if line[:13] == \"LLC WRITEBACK\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_wb = int(line.split()[7])\n",
    "                        prev_accesses_wb = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        wb_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_wb\n",
    "                        prev_misses_wb = int(line.split()[7])\n",
    "                        wb_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_wb\n",
    "                        prev_accesses_wb = int(line.split()[3])\n",
    "            if not checker or ctr != 751:\n",
    "                print(\"\\n Error:\", fname) # Check if a file didn't finish correctly\n",
    "    print(\"|\",end=\"\")\n",
    "    #print(l1d_small)\n",
    "    wb_accesses['id'] = file[:-9] + '_' + wb_accesses.index.map(str)\n",
    "    wb_misses['id'] = file[:-9] + '_' + wb_misses.index.map(str)\n",
    "    \n",
    "    #print(l1d_small)\n",
    "    wb_accesses_full = pd.concat([wb_accesses_full, wb_accesses], ignore_index = True)\n",
    "    wb_misses_full = pd.concat([wb_misses_full, wb_misses], ignore_index = True)\n",
    "    print(wb_misses_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_accesses_full.to_csv('caches/llc_writeback_accesses.csv',index=False)\n",
    "wb_misses_full.to_csv('caches/llc_writeback_misses.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca73b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../ce_raw_data/raw_data/'\n",
    "id_ctr = 0\n",
    "columns = ['id','32','64','128','256','512','1024','2048','4096','8192']\n",
    "wb_accesses_full = pd.DataFrame()\n",
    "wb_misses_full = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    if file[-9:] != '_2048.out':\n",
    "        continue\n",
    "    wb_accesses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    wb_misses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    for c in columns[1:]:\n",
    "        fname = file[:-9] + '_' + c + '.out'\n",
    "        checker = False\n",
    "        with open(path+fname) as f:\n",
    "            lines = f.readlines()\n",
    "            ctr = 0\n",
    "            prev_misses_l1d = 0.\n",
    "            prev_accesses_l1d = 0.\n",
    "            prev_misses_wb = 0.\n",
    "            prev_accesses_wb = 0.\n",
    "            for line in lines:\n",
    "                if line == \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "                    checker=True\n",
    "                if line[:14] == \"cpu0_L1D TOTAL\":\n",
    "                    ctr+=1\n",
    "                if line[:13] == \"LLC WRITEBACK\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_wb = int(line.split()[7])\n",
    "                        prev_accesses_wb = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        wb_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_wb\n",
    "                        prev_misses_wb = int(line.split()[7])\n",
    "                        wb_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_wb\n",
    "                        prev_accesses_wb = int(line.split()[3])\n",
    "            if not checker or ctr != 751:\n",
    "                print(\"\\n Error:\", fname) # Check if a file didn't finish correctly\n",
    "    print(\"|\",end=\"\")\n",
    "    #print(l1d_small)\n",
    "    wb_accesses['id'] = file[:-9] + '_' + wb_accesses.index.map(str)\n",
    "    wb_misses['id'] = file[:-9] + '_' + wb_misses.index.map(str)\n",
    "    \n",
    "    #print(l1d_small)\n",
    "    wb_accesses_full = pd.concat([wb_accesses_full, wb_accesses], ignore_index = True)\n",
    "    wb_misses_full = pd.concat([wb_misses_full, wb_misses], ignore_index = True)\n",
    "    print(wb_misses_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbaf8a",
   "metadata": {},
   "source": [
    "# Raw data -> load + rfo accesses, misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed81794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318c9a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
     ]
    }
   ],
   "source": [
    "path = '../ce_raw_data/l2c512/'\n",
    "id_ctr = 0\n",
    "#columns = ['id','1024','2048','4096','8192']\n",
    "columns = ['id','2048','4096']\n",
    "load_accesses_full = pd.DataFrame()\n",
    "load_misses_full = pd.DataFrame()\n",
    "rfo_accesses_full = pd.DataFrame()\n",
    "rfo_misses_full = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    if file[-9:] != '_2048.out':\n",
    "        continue\n",
    "    load_accesses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    load_misses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    rfo_accesses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    rfo_misses = pd.DataFrame(0., index=np.arange(749), columns=columns)\n",
    "    for c in columns[1:]:\n",
    "        fname = file[:-9] + '_' + c + '.out'\n",
    "        checker = False\n",
    "        with open(path+fname) as f:\n",
    "            lines = f.readlines()\n",
    "            ctr = 0\n",
    "            prev_misses_load = 0.\n",
    "            prev_accesses_load = 0.\n",
    "            prev_misses_rfo = 0.\n",
    "            prev_accesses_rfo = 0.\n",
    "            for line in lines:\n",
    "                if line == \"~~~~~~~~~~Reuse Distance Profiler output~~~~~~~~~~\\n\":\n",
    "                    checker=True\n",
    "                if line[:14] == \"cpu0_L1D TOTAL\":\n",
    "                    ctr+=1\n",
    "                if line[:8] == \"LLC LOAD\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_load = int(line.split()[7])\n",
    "                        prev_accesses_load = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        load_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_load\n",
    "                        prev_misses_load = int(line.split()[7])\n",
    "                        load_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_load\n",
    "                        prev_accesses_load = int(line.split()[3])\n",
    "                if line[:7] == \"LLC RFO\":\n",
    "                    if ctr == 1:\n",
    "                        prev_misses_rfo = int(line.split()[7])\n",
    "                        prev_accesses_rfo = int(line.split()[3])\n",
    "                    if 751 > ctr and ctr > 1:\n",
    "                        rfo_misses[c][ctr-2] = int(line.split()[7]) - prev_misses_rfo\n",
    "                        prev_misses_rfo = int(line.split()[7])\n",
    "                        rfo_accesses[c][ctr-2] = int(line.split()[3]) - prev_accesses_rfo\n",
    "                        prev_accesses_rfo = int(line.split()[3])\n",
    "            if not checker or ctr != 751:\n",
    "                print(\"\\n Error:\", fname) # Check if a file didn't finish correctly\n",
    "    print(\"|\",end=\"\")\n",
    "    rfo_accesses['id'] = file[:-9] + '_' + rfo_accesses.index.map(str)\n",
    "    rfo_misses['id'] = file[:-9] + '_' + rfo_misses.index.map(str)\n",
    "    load_misses['id'] = file[:-9] + '_' + rfo_accesses.index.map(str)\n",
    "    load_accesses['id'] = file[:-9] + '_' + rfo_misses.index.map(str)\n",
    "    rfo_accesses_full = pd.concat([rfo_accesses_full, rfo_accesses], ignore_index = True)\n",
    "    rfo_misses_full = pd.concat([rfo_misses_full, rfo_misses], ignore_index = True)\n",
    "    load_accesses_full = pd.concat([load_accesses_full, load_accesses], ignore_index = True)\n",
    "    load_misses_full = pd.concat([load_misses_full, load_misses], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb85d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = 'l2c512'\n",
    "rfo_accesses_full.to_csv(cache_path + '/llc_rfo_accesses.csv',index=False)\n",
    "rfo_misses_full.to_csv(cache_path + '/llc_rfo_misses.csv',index=False)\n",
    "load_accesses_full.to_csv(cache_path + '/llc_load_accesses.csv',index=False)\n",
    "load_misses_full.to_csv(cache_path + '/llc_load_misses.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e721e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id   2048   4096\n",
      "0       400.perlbench-41B_0  594.0  594.0\n",
      "1       400.perlbench-41B_1  767.0  767.0\n",
      "2       400.perlbench-41B_2  477.0  477.0\n",
      "3       400.perlbench-41B_3  279.0  279.0\n",
      "4       400.perlbench-41B_4  520.0  520.0\n",
      "...                     ...    ...    ...\n",
      "141556     657.xz_s-56B_744  838.0  838.0\n",
      "141557     657.xz_s-56B_745  836.0  836.0\n",
      "141558     657.xz_s-56B_746  838.0  838.0\n",
      "141559     657.xz_s-56B_747  836.0  836.0\n",
      "141560     657.xz_s-56B_748  836.0  836.0\n",
      "\n",
      "[141561 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(load_accesses_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c0337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
